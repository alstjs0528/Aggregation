{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b8314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, plot_confusion_matrix\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044df6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = pd.read_csv('144612_PDB_Database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b98622",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_static = DB['Static']\n",
    "y_dynamic = DB['Dynamic']\n",
    "y_static_class = DB['Static Class']\n",
    "y_dynamic_class = DB['Dynamic Class']\n",
    "X = DB.drop(['Static','Dynamic','Static Class','Dynamic Class'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6193ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_plot(y_test,y_predict):\n",
    "    plt.figure(figsize=(5,5),dpi=300)\n",
    "    plt.rc('axes', labelsize=18) \n",
    "    plt.scatter(y_test,y_predict,alpha = 0.2,color='blue')\n",
    "    plt.xlabel('Actual value'); plt.ylabel('Predicted value')\n",
    "    plt.plot([-5,5],[-5,5],color=\"red\")\n",
    "    plt.xlim(-5,5); plt.ylim(-5,5)\n",
    "    plt.xticks(np.arange(-5,6,1)); plt.yticks(np.arange(-5,6,1))\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state=0,n_estimators=200,learning_rate=0.2,max_depth=6) # static_regression\n",
    "#xgb = XGBRegressor(random_state=0,n_estimators=200,learning_rate=0.2,max_depth=6) # dynamic_regression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_static, train_size =0.8, random_state = 0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_dynamic, train_size =0.8, random_state = 0)\n",
    "\n",
    "models = [xgb]\n",
    "models_n = ['XGB']    \n",
    "\n",
    "\n",
    "for clf_n,clf in zip(models_n,models):\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # fi = clf.feature_importances_\n",
    "        \n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    rmse = (mean_squared_error(y_test,y_pred))**0.5\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "    print('Model: {} - MAE :{:.4f} | RMSE :{:.4f} | R2 :{:.4f}'.format(clf_n,mae,rmse,r2))\n",
    "    regression_plot(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=0,n_estimators=200,learning_rate=0.1,max_depth=6) # static_classification\n",
    "#xgb = XGBClassifier(random_state=0,n_estimators=200,learning_rate=0.1,max_depth=6) # dynamic_classification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_static_class, train_size =0.8, random_state = 0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y_dynamic_class, train_size =0.8, random_state = 0)\n",
    "\n",
    "models = [xgb]\n",
    "models_n = ['XGB']    \n",
    "\n",
    "PRED = pd.DataFrame()\n",
    "ACC = pd.DataFrame()\n",
    "PRECISION = pd.DataFrame()\n",
    "RECALL = pd.DataFrame()\n",
    "F1 = pd.DataFrame()\n",
    "FI = pd.DataFrame()\n",
    "\n",
    "for clf_n,clf in zip(models_n,models):\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # fi = clf.feature_importances_\n",
    "    \n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    plot_confusion_matrix(clf, X_test, y_test, cmap = 'Blues')\n",
    "    plt.show()\n",
    "    print('Model: {} - ACC :{:.4f} | PRECISION :{:.4f} | RECALL :{:.4f} | F1 :{:.4f}'.format(clf_n,acc,precision,recall,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state=0,n_estimators=200,learning_rate=0.2,max_depth=6) # static_regression\n",
    "#xgb = XGBRegressor(random_state=0,n_estimators=200,learning_rate=0.2,max_depth=6) # dynamic_regression\n",
    "#xgb = XGBClassifier(random_state=0,n_estimators=200,learning_rate=0.1,max_depth=6) # static_classification\n",
    "#xgb = XGBClassifier(random_state=0,n_estimators=200,learning_rate=0.1,max_depth=6) # dynamic_classification\n",
    "\n",
    "\n",
    "XGB = xgb.fit(X,y_static)\n",
    "XGB = xgb.fit(X,y_dynamic)\n",
    "XGB = xgb.fit(X,y_static_class)\n",
    "XGB = xgb.fit(X,y_dynamic_class)\n",
    "\n",
    "explainer = shap.TreeExplainer(XGB)\n",
    "shap_values = explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values, X)\n",
    "plt.savefig('static_cla.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
